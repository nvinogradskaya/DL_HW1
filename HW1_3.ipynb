{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bda71bb-e078-41d1-ab0a-383df445becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f930948-c983-4062-9120-ad8ecca8f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('train_x.csv')\n",
    "labels_df = pd.read_csv('train_y.csv')\n",
    "features_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "labels_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "mask = (labels_df['year'] == 2000) | (labels_df['year'] == 2002)\n",
    "X_features = features_df[mask].to_numpy()\n",
    "y_labels = labels_df[mask].replace({2000: 0, 2002: 1}).to_numpy().ravel()\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "309ad8e1-ef27-4961-8267-c4d95aab8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + torch.exp(-z))\n",
    "    \n",
    "def compute_nll(predictions, targets):\n",
    "    epsilon = 1e-10\n",
    "    predictions = torch.clamp(predictions, epsilon, 1 - epsilon)\n",
    "    return - (targets * torch.log(predictions) + (1 - targets) * torch.log(1 - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d87ef265-2e19-404c-9f56-3bd6dc97e54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMomentum — метод, который ускоряет обучение, помогая модели преодолевать локальные минимумы, колебания \\nи медленные изменения в градиентах. Он добавляет \"инерцию\" в обновление весов, чтобы избежать застревания на плато \\nи быстрее достичь глобального минимума\\n\\nвместо простого обновления весов на основе градиента текущей итерации, \\nон добавляет часть изменения из предыдущей итерации -- это позволяет моделям лучше справляться с ситуациями, \\nгде градиенты колеблются или изменяются медленно\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Momentum — метод, который ускоряет обучение, помогая модели преодолевать локальные минимумы, колебания \n",
    "и медленные изменения в градиентах. Он добавляет \"инерцию\" в обновление весов, чтобы избежать застревания на плато \n",
    "и быстрее достичь глобального минимума\n",
    "\n",
    "вместо простого обновления весов на основе градиента текущей итерации, \n",
    "он добавляет часть изменения из предыдущей итерации -- это позволяет моделям лучше справляться с ситуациями, \n",
    "где градиенты колеблются или изменяются медленно\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1e0c3a9-e681-46f2-b5f5-3703781e062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neuron_momentum(X, y, w, b, lr, epochs, momentum=0.9):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float64)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float64)    \n",
    "    w_tensor = torch.tensor(w, dtype=torch.float64)\n",
    "    b_tensor = torch.tensor(b, dtype=torch.float64)\n",
    "    w_vel = torch.zeros_like(w_tensor)\n",
    "    b_vel = 0.0\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        w_grad_sum = torch.zeros_like(w_tensor)\n",
    "        b_grad_sum = 0.0\n",
    "        for i in range(len(X_tensor)):\n",
    "            x_sample = X_tensor[i]\n",
    "            y_sample = y_tensor[i]\n",
    "            z = torch.dot(w_tensor, x_sample) + b_tensor\n",
    "            y_pred = sigmoid(z)\n",
    "            \n",
    "            loss = compute_nll(y_pred, y_sample)\n",
    "            total_loss += loss.item()\n",
    "            error = y_pred - y_sample\n",
    "            w_grad = error * x_sample\n",
    "            b_grad = error            \n",
    "            w_grad_sum += w_grad\n",
    "            b_grad_sum += b_grad\n",
    "        \n",
    "        w_grad_mean = w_grad_sum / len(X_tensor)\n",
    "        b_grad_mean = b_grad_sum / len(X_tensor)\n",
    "        \n",
    "        w_vel = momentum * w_vel + lr * w_grad_mean\n",
    "        b_vel = momentum * b_vel + lr * b_grad_mean\n",
    "        \n",
    "        w_tensor -= w_vel\n",
    "        b_tensor -= b_vel\n",
    "        \n",
    "        avg_loss = total_loss / len(X_tensor)\n",
    "        loss_history.append(round(avg_loss, 4))    \n",
    "    final_w = [round(w.item(), 4) for w in w_tensor]\n",
    "    final_b = round(b_tensor.item(), 4)    \n",
    "    return final_w, final_b, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "473ae3da-487c-4739-b9a4-5b57d2f8706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_M: [-0.3338, -0.3373, 0.4687, -0.8793, -0.516, 0.2786, 0.4686, 0.7099, -0.0656, 0.3466, 0.4958, 0.1603, 0.2726, -0.832, -0.5146, 0.3351, 0.4343, -0.1121, -0.2126, 0.0574, -0.009, 0.6218, 0.1545, 0.1761, -0.5171, 0.247, -0.2252, -0.4442, 0.1481, 0.0947, -0.3943, 0.0816, 0.2533, 0.163, 0.527, 0.1665, -0.6695, 0.4131, 0.5771, 0.5059, -0.1063, -0.1156, 0.4422, -0.0389, 0.3211, -0.0151, -0.3667, -0.773, 0.0108, -0.7143, -0.6759, 0.163, -0.2537, -0.1108, -0.5247, -0.3019, 0.0399, -0.7635, -0.565, -0.4119, 0.3724, -0.2494, 0.1358, -0.6232, 0.7708, -0.0226, 0.5702, 0.7382, -0.2454, 0.3907, 0.2027, 0.3046, 0.2679, 0.472, 0.4601, -0.4101, 0.1319, -0.3877, -0.5047, -0.1142, -0.2561, -0.6059, -0.5532, -0.0679, 0.1464, -0.315, -0.0639, 0.233, 0.0442, 0.1921]\n",
      "\n",
      "bias_M: 0.077\n",
      "\n",
      "loss_M: [1.8315, 1.8007, 1.7512, 1.693, 1.6335, 1.5772, 1.5258, 1.4789, 1.4363, 1.3961, 1.3584, 1.3235, 1.291, 1.2605, 1.2318, 1.2046, 1.1788, 1.1543, 1.1309, 1.1087]\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.random.uniform(-1, 1, X_normalized.shape[1])\n",
    "initial_b = 0.0\n",
    "lr = 0.1\n",
    "epochs = 20\n",
    "momentum = 0.7  \n",
    "\n",
    "w_momentum, b_momentum, loss_momentum = train_neuron_momentum(\n",
    "    X_normalized, y_labels, initial_w, initial_b, lr, epochs, momentum)\n",
    "print(\"weights_M:\", w_momentum)\n",
    "print()\n",
    "print(\"bias_M:\", b_momentum)\n",
    "print()\n",
    "print(\"loss_M:\", loss_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b19d9703-1883-429e-93da-6ab7841bc0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_M: 52.41%\n"
     ]
    }
   ],
   "source": [
    "predictions_momentum = sigmoid(torch.matmul(torch.tensor(X_normalized, dtype=torch.float64), torch.tensor(w_momentum, dtype=torch.float64)) + b_momentum)\n",
    "rounded_predictions_momentum = torch.round(predictions_momentum)\n",
    "accuracy_momentum = (rounded_predictions_momentum.numpy() == y_labels).mean()\n",
    "print(f\"accuracy_M: {round(accuracy_momentum * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3e500-dd83-4052-b7f9-e862d6013ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
